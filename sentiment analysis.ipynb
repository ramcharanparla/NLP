{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d6bc579-ead5-484c-a1c6-1ed124c2ed9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>asin</th>\n",
       "      <th>helpful</th>\n",
       "      <th>rating</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>11539</td>\n",
       "      <td>B0033UV8HI</td>\n",
       "      <td>[8, 10]</td>\n",
       "      <td>3</td>\n",
       "      <td>Jace Rankin may be short, but he's nothing to ...</td>\n",
       "      <td>09 2, 2010</td>\n",
       "      <td>A3HHXRELK8BHQG</td>\n",
       "      <td>Ridley</td>\n",
       "      <td>Entertaining But Average</td>\n",
       "      <td>1283385600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5957</td>\n",
       "      <td>B002HJV4DE</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>5</td>\n",
       "      <td>Great short read.  I didn't want to put it dow...</td>\n",
       "      <td>10 8, 2013</td>\n",
       "      <td>A2RGNZ0TRF578I</td>\n",
       "      <td>Holly Butler</td>\n",
       "      <td>Terrific menage scenes!</td>\n",
       "      <td>1381190400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>9146</td>\n",
       "      <td>B002ZG96I4</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>3</td>\n",
       "      <td>I'll start by saying this is the first of four...</td>\n",
       "      <td>04 11, 2014</td>\n",
       "      <td>A3S0H2HV6U1I7F</td>\n",
       "      <td>Merissa</td>\n",
       "      <td>Snapdragon Alley</td>\n",
       "      <td>1397174400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7038</td>\n",
       "      <td>B002QHWOEU</td>\n",
       "      <td>[1, 3]</td>\n",
       "      <td>3</td>\n",
       "      <td>Aggie is Angela Lansbury who carries pocketboo...</td>\n",
       "      <td>07 5, 2014</td>\n",
       "      <td>AC4OQW3GZ919J</td>\n",
       "      <td>Cleargrace</td>\n",
       "      <td>very light murder cozy</td>\n",
       "      <td>1404518400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1776</td>\n",
       "      <td>B001A06VJ8</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>4</td>\n",
       "      <td>I did not expect this type of book to be in li...</td>\n",
       "      <td>12 31, 2012</td>\n",
       "      <td>A3C9V987IQHOQD</td>\n",
       "      <td>Rjostler</td>\n",
       "      <td>Book</td>\n",
       "      <td>1356912000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11995</th>\n",
       "      <td>11995</td>\n",
       "      <td>2183</td>\n",
       "      <td>B001DUGORO</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>4</td>\n",
       "      <td>Valentine cupid is a vampire- Jena and Ian ano...</td>\n",
       "      <td>02 28, 2014</td>\n",
       "      <td>A1OKS5Q1HD8WQC</td>\n",
       "      <td>lisa jon jung</td>\n",
       "      <td>jena</td>\n",
       "      <td>1393545600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11996</th>\n",
       "      <td>11996</td>\n",
       "      <td>6272</td>\n",
       "      <td>B002JCSFSQ</td>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>5</td>\n",
       "      <td>I have read all seven books in this series. Ap...</td>\n",
       "      <td>05 16, 2011</td>\n",
       "      <td>AQRSPXLNEQAMA</td>\n",
       "      <td>TerryLP</td>\n",
       "      <td>Peacekeepers Series</td>\n",
       "      <td>1305504000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11997</th>\n",
       "      <td>11997</td>\n",
       "      <td>12483</td>\n",
       "      <td>B0035N1V7K</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>3</td>\n",
       "      <td>This book really just wasn't my cuppa.  The si...</td>\n",
       "      <td>07 26, 2013</td>\n",
       "      <td>A2T5QLT5VXOJAK</td>\n",
       "      <td>hwilson</td>\n",
       "      <td>a little creepy</td>\n",
       "      <td>1374796800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11998</th>\n",
       "      <td>11998</td>\n",
       "      <td>3640</td>\n",
       "      <td>B001W1XT40</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>1</td>\n",
       "      <td>tried to use it to charge my kindle, it didn't...</td>\n",
       "      <td>09 17, 2013</td>\n",
       "      <td>A28MHD2DDY6DXB</td>\n",
       "      <td>Allison A. Slater \"Gryphon50\"</td>\n",
       "      <td>didn't work</td>\n",
       "      <td>1379376000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11999</th>\n",
       "      <td>11999</td>\n",
       "      <td>11398</td>\n",
       "      <td>B003370JUS</td>\n",
       "      <td>[5, 6]</td>\n",
       "      <td>3</td>\n",
       "      <td>Taking Instruction is a look into the often hi...</td>\n",
       "      <td>07 5, 2012</td>\n",
       "      <td>A3JUXLB4K9ZXCC</td>\n",
       "      <td>Dafna Yee</td>\n",
       "      <td>If you like BDSM with a touch of romance, this...</td>\n",
       "      <td>1341446400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0.1  Unnamed: 0        asin  helpful  rating  \\\n",
       "0                 0       11539  B0033UV8HI  [8, 10]       3   \n",
       "1                 1        5957  B002HJV4DE   [1, 1]       5   \n",
       "2                 2        9146  B002ZG96I4   [0, 0]       3   \n",
       "3                 3        7038  B002QHWOEU   [1, 3]       3   \n",
       "4                 4        1776  B001A06VJ8   [0, 1]       4   \n",
       "...             ...         ...         ...      ...     ...   \n",
       "11995         11995        2183  B001DUGORO   [0, 0]       4   \n",
       "11996         11996        6272  B002JCSFSQ   [2, 2]       5   \n",
       "11997         11997       12483  B0035N1V7K   [0, 1]       3   \n",
       "11998         11998        3640  B001W1XT40   [1, 2]       1   \n",
       "11999         11999       11398  B003370JUS   [5, 6]       3   \n",
       "\n",
       "                                              reviewText   reviewTime  \\\n",
       "0      Jace Rankin may be short, but he's nothing to ...   09 2, 2010   \n",
       "1      Great short read.  I didn't want to put it dow...   10 8, 2013   \n",
       "2      I'll start by saying this is the first of four...  04 11, 2014   \n",
       "3      Aggie is Angela Lansbury who carries pocketboo...   07 5, 2014   \n",
       "4      I did not expect this type of book to be in li...  12 31, 2012   \n",
       "...                                                  ...          ...   \n",
       "11995  Valentine cupid is a vampire- Jena and Ian ano...  02 28, 2014   \n",
       "11996  I have read all seven books in this series. Ap...  05 16, 2011   \n",
       "11997  This book really just wasn't my cuppa.  The si...  07 26, 2013   \n",
       "11998  tried to use it to charge my kindle, it didn't...  09 17, 2013   \n",
       "11999  Taking Instruction is a look into the often hi...   07 5, 2012   \n",
       "\n",
       "           reviewerID                   reviewerName  \\\n",
       "0      A3HHXRELK8BHQG                         Ridley   \n",
       "1      A2RGNZ0TRF578I                   Holly Butler   \n",
       "2      A3S0H2HV6U1I7F                        Merissa   \n",
       "3       AC4OQW3GZ919J                     Cleargrace   \n",
       "4      A3C9V987IQHOQD                       Rjostler   \n",
       "...               ...                            ...   \n",
       "11995  A1OKS5Q1HD8WQC                  lisa jon jung   \n",
       "11996   AQRSPXLNEQAMA                        TerryLP   \n",
       "11997  A2T5QLT5VXOJAK                        hwilson   \n",
       "11998  A28MHD2DDY6DXB  Allison A. Slater \"Gryphon50\"   \n",
       "11999  A3JUXLB4K9ZXCC                      Dafna Yee   \n",
       "\n",
       "                                                 summary  unixReviewTime  \n",
       "0                               Entertaining But Average      1283385600  \n",
       "1                                Terrific menage scenes!      1381190400  \n",
       "2                                       Snapdragon Alley      1397174400  \n",
       "3                                 very light murder cozy      1404518400  \n",
       "4                                                   Book      1356912000  \n",
       "...                                                  ...             ...  \n",
       "11995                                               jena      1393545600  \n",
       "11996                                Peacekeepers Series      1305504000  \n",
       "11997                                    a little creepy      1374796800  \n",
       "11998                                        didn't work      1379376000  \n",
       "11999  If you like BDSM with a touch of romance, this...      1341446400  \n",
       "\n",
       "[12000 rows x 11 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('kindle_sentiment/all_kindle_review.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d885935c-8e00-4d2e-9ee7-fb7fda190c93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jace Rankin may be short, but he's nothing to ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Great short read.  I didn't want to put it dow...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'll start by saying this is the first of four...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aggie is Angela Lansbury who carries pocketboo...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I did not expect this type of book to be in li...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11995</th>\n",
       "      <td>Valentine cupid is a vampire- Jena and Ian ano...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11996</th>\n",
       "      <td>I have read all seven books in this series. Ap...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11997</th>\n",
       "      <td>This book really just wasn't my cuppa.  The si...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11998</th>\n",
       "      <td>tried to use it to charge my kindle, it didn't...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11999</th>\n",
       "      <td>Taking Instruction is a look into the often hi...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              reviewText  rating\n",
       "0      Jace Rankin may be short, but he's nothing to ...       3\n",
       "1      Great short read.  I didn't want to put it dow...       5\n",
       "2      I'll start by saying this is the first of four...       3\n",
       "3      Aggie is Angela Lansbury who carries pocketboo...       3\n",
       "4      I did not expect this type of book to be in li...       4\n",
       "...                                                  ...     ...\n",
       "11995  Valentine cupid is a vampire- Jena and Ian ano...       4\n",
       "11996  I have read all seven books in this series. Ap...       5\n",
       "11997  This book really just wasn't my cuppa.  The si...       3\n",
       "11998  tried to use it to charge my kindle, it didn't...       1\n",
       "11999  Taking Instruction is a look into the often hi...       3\n",
       "\n",
       "[12000 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = data[['reviewText','rating']]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2f6f580-83c9-4a33-930d-8f79332cad74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rating\n",
       "5    3000\n",
       "4    3000\n",
       "3    2000\n",
       "2    2000\n",
       "1    2000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['rating'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b6c6e03-2eec-4ec4-ba24-cb96da141e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# positive review 1 and negative review 0\n",
    "df.loc[:,'rating']=df['rating'].apply(lambda x:0 if x<=3 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8306224-1e2c-4385-ad2e-ea982f6da718",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rating\n",
       "0    6000\n",
       "1    6000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['rating'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed35ba0c-22bb-473a-bf20-e754859220ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:,'reviewText']=df['reviewText'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ccaa2bb-9602-45f3-b3eb-5135d9d4a4db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jace rankin may be short, but he's nothing to ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>great short read.  i didn't want to put it dow...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i'll start by saying this is the first of four...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aggie is angela lansbury who carries pocketboo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i did not expect this type of book to be in li...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  rating\n",
       "0  jace rankin may be short, but he's nothing to ...       0\n",
       "1  great short read.  i didn't want to put it dow...       1\n",
       "2  i'll start by saying this is the first of four...       0\n",
       "3  aggie is angela lansbury who carries pocketboo...       0\n",
       "4  i did not expect this type of book to be in li...       1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b942894-8930-4229-9ff2-08311997a6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33b25d2-a5f8-4d8f-ab29-3aa7140e303b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing special charaters\n",
    "df.loc[:,'reviewText']=df['reviewText'].apply(lambda x: re.sub('[^a-z A-Z 0-9]','',x))\n",
    "# Removing the stopwords\n",
    "df.loc[:,'reviewText']=df['reviewText'].apply(lambda x:\" \".join([y for y in x.split() if y not in stopwords.words('english')]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5a76dc3f-c252-45dc-aa16-9b98e5d3a149",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\s'\n",
      "C:\\Users\\Ramcharan\\AppData\\Local\\Temp\\ipykernel_10800\\1545105592.py:2: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  df['reviewText'].apply(lambda x: re.search('https?://[^\\s]+(\\.com|\\.org|\\.net)',x))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0        None\n",
       "1        None\n",
       "2        None\n",
       "3        None\n",
       "4        None\n",
       "         ... \n",
       "11995    None\n",
       "11996    None\n",
       "11997    None\n",
       "11998    None\n",
       "11999    None\n",
       "Name: reviewText, Length: 12000, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for url and remove URL\n",
    "df['reviewText'].apply(lambda x: re.search('https?://[^\\s]+(\\.com|\\.org|\\.net)',x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6d416025-acc9-4434-a00e-061355ced51e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        []\n",
      "1        []\n",
      "2        []\n",
      "3        []\n",
      "4        []\n",
      "         ..\n",
      "11995    []\n",
      "11996    []\n",
      "11997    []\n",
      "11998    []\n",
      "11999    []\n",
      "Name: reviewText, Length: 12000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Function to extract HTML tags\n",
    "def extract_html_tags(value):\n",
    "    return re.findall(r'<[^>]+>', str(value))\n",
    "\n",
    "# Apply the function to extract HTML tags\n",
    "dd = df['reviewText'].apply(extract_html_tags)\n",
    "\n",
    "print(dd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0d76ea41-0581-41f6-b109-351be7f30092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove any additional spaces\n",
    "df.loc[:,'reviewText']=df['reviewText'].apply(lambda x:' '.join(x.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd503f24-2467-4232-957c-ec2c6e849a59",
   "metadata": {},
   "source": [
    "##### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c844e180-754e-4326-86ee-04fdc131964d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "389c32b4-f5b0-4280-83e0-70261a89a323",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "# Define a function to lemmatize text\n",
    "def lemmatize_text(text):\n",
    "    tokens = word_tokenize(text)  # Tokenize the text\n",
    "    lemmatized = [lemmatizer.lemmatize(token) for token in tokens]  # Lemmatize each word\n",
    "    return ' '.join(lemmatized)  # Join tokens back into a single string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6282258f-4721-4c37-b7d8-8df1caecafa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to the reviewText column\n",
    "df.loc[:,'reviewText'] = df['reviewText'].apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb75f5b-a6b5-4888-98e5-da6c8d256a8b",
   "metadata": {},
   "source": [
    "##### Train Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cadc9fda-445a-406f-9b84-78241529b27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['reviewText'],df['rating'],test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9c12b123-7959-439d-a8b9-d2489fd99a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf.fit_transform(X_train).toarray()\n",
    "X_test_tfidf = tfidf.transform(X_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f3272f03-fa9a-42a8-a960-12f177b8f31a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "cbba12b7-d4e6-47d3-b21b-c2c7b8651f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb_model_tfidf = GaussianNB().fit(X_train_tfidf,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "fdb86851-dcb5-4449-91a7-4a6953b7c939",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0d89db11-ff38-405e-b408-c3c07dabe776",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_tfidf = nb_model_tfidf.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6e871e6d-d8b8-4912-81b9-7ed3128fd5a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1048,  429],\n",
       "       [ 601,  922]], dtype=int64)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_pred_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "df8861db-2560-40be-8ff1-72e2a721b94c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6566666666666666"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_pred_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1cc48fbd-da9b-490f-adff-72fc78c7b99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ed90da25-fda3-41c5-a63b-d0a4cad4d53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "5c7f1873-8647-4218-9b2b-6987396d7201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the Naive Bayes model using Word2Vec: 0.61\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Step 1: Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['reviewText'], df['rating'], test_size=0.25, random_state=42)\n",
    "\n",
    "# Step 2: Tokenize the text data (Word2Vec requires tokenized input)\n",
    "X_train_tokens = X_train.apply(lambda x: x.split())\n",
    "X_test_tokens = X_test.apply(lambda x: x.split())\n",
    "\n",
    "# Step 3: Train a Word2Vec model on the training data\n",
    "w2v_model = Word2Vec(sentences=X_train, vector_size=100, window=5, min_count=1, workers=4, seed=42)\n",
    "\n",
    "# Step 4: Create a function to convert each review to a single vector by averaging word vectors\n",
    "def vectorize_text(tokens, model, vector_size=100):\n",
    "    \"\"\"\n",
    "    Convert a list of tokens into a single vector by averaging their Word2Vec embeddings.\n",
    "    If a token is not in the model, it is ignored.\n",
    "    \"\"\"\n",
    "    vectors = [model.wv[word] for word in tokens if word in model.wv]\n",
    "    if len(vectors) > 0:\n",
    "        return np.mean(vectors, axis=0)\n",
    "    else:\n",
    "        # Return a zero vector if none of the tokens are in the Word2Vec vocabulary\n",
    "        return np.zeros(vector_size)\n",
    "\n",
    "# Step 5: Vectorize the training and testing data\n",
    "X_train_vectors = np.array([vectorize_text(tokens, w2v_model) for tokens in X_train])\n",
    "X_test_vectors = np.array([vectorize_text(tokens, w2v_model) for tokens in X_test])\n",
    "\n",
    "# Step 6: Train a Naive Bayes model using the Word2Vec features\n",
    "xg_boost_model = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0)\n",
    "xg_boost_model.fit(X_train_vectors, y_train)\n",
    "\n",
    "# Step 7: Evaluate the model\n",
    "accuracy = xg_boost_model.score(X_test_vectors, y_test)\n",
    "print(f\"Accuracy of the Naive Bayes model using Word2Vec: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c438dc-73c5-4403-85ba-24a3f59b934d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
